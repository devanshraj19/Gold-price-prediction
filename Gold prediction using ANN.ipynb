{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "980ec68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc46fe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f78d23f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ff9f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Devansh Raj/Downloads/gold_price_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d9fe838f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SPX</th>\n",
       "      <th>GLD</th>\n",
       "      <th>USO</th>\n",
       "      <th>SLV</th>\n",
       "      <th>EUR/USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/08</td>\n",
       "      <td>1447.160034</td>\n",
       "      <td>84.860001</td>\n",
       "      <td>78.470001</td>\n",
       "      <td>15.180</td>\n",
       "      <td>1.471692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/03/08</td>\n",
       "      <td>1447.160034</td>\n",
       "      <td>85.570000</td>\n",
       "      <td>78.370003</td>\n",
       "      <td>15.285</td>\n",
       "      <td>1.474491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/04/08</td>\n",
       "      <td>1411.630005</td>\n",
       "      <td>85.129997</td>\n",
       "      <td>77.309998</td>\n",
       "      <td>15.167</td>\n",
       "      <td>1.475492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/07/08</td>\n",
       "      <td>1416.180054</td>\n",
       "      <td>84.769997</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>15.053</td>\n",
       "      <td>1.468299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/08/08</td>\n",
       "      <td>1390.189941</td>\n",
       "      <td>86.779999</td>\n",
       "      <td>76.059998</td>\n",
       "      <td>15.590</td>\n",
       "      <td>1.557099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date          SPX        GLD        USO     SLV   EUR/USD\n",
       "0  01/02/08  1447.160034  84.860001  78.470001  15.180  1.471692\n",
       "1  01/03/08  1447.160034  85.570000  78.370003  15.285  1.474491\n",
       "2  01/04/08  1411.630005  85.129997  77.309998  15.167  1.475492\n",
       "3  01/07/08  1416.180054  84.769997  75.500000  15.053  1.468299\n",
       "4  01/08/08  1390.189941  86.779999  76.059998  15.590  1.557099"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "036abf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df[['SPX','USO', 'SLV', 'EUR/USD']]\n",
    "y= df[['GLD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5697c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7ae03dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6ad27f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled=scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e09730c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6513da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='relu',input_dim=4))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c3952a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "03d6ea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 13475.3330 - val_loss: 11044.5967\n",
      "Epoch 2/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 10278.6182 - val_loss: 7427.1177\n",
      "Epoch 3/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 6353.3931 - val_loss: 3951.7881\n",
      "Epoch 4/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 3163.2485 - val_loss: 1725.6134\n",
      "Epoch 5/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1384.0734 - val_loss: 828.1362\n",
      "Epoch 6/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 726.8034 - val_loss: 610.9630\n",
      "Epoch 7/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 558.0473 - val_loss: 581.3132\n",
      "Epoch 8/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 514.7178 - val_loss: 567.5719\n",
      "Epoch 9/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 492.5347 - val_loss: 549.0543\n",
      "Epoch 10/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 473.7703 - val_loss: 528.5686\n",
      "Epoch 11/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 455.3661 - val_loss: 505.8271\n",
      "Epoch 12/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 437.7509 - val_loss: 485.6987\n",
      "Epoch 13/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 421.0901 - val_loss: 464.9106\n",
      "Epoch 14/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 405.1209 - val_loss: 444.5216\n",
      "Epoch 15/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 389.4963 - val_loss: 426.9697\n",
      "Epoch 16/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 374.5373 - val_loss: 408.6196\n",
      "Epoch 17/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 360.3065 - val_loss: 390.2489\n",
      "Epoch 18/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 346.4569 - val_loss: 373.6276\n",
      "Epoch 19/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 333.1976 - val_loss: 357.5029\n",
      "Epoch 20/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 320.6172 - val_loss: 341.9407\n",
      "Epoch 21/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 308.3062 - val_loss: 325.6421\n",
      "Epoch 22/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 296.5247 - val_loss: 310.3147\n",
      "Epoch 23/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 285.0966 - val_loss: 298.1697\n",
      "Epoch 24/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 274.2054 - val_loss: 285.6142\n",
      "Epoch 25/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 263.7395 - val_loss: 271.6994\n",
      "Epoch 26/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 253.8302 - val_loss: 258.9427\n",
      "Epoch 27/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 244.3882 - val_loss: 247.9991\n",
      "Epoch 28/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 235.1112 - val_loss: 237.6999\n",
      "Epoch 29/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 226.4549 - val_loss: 225.7041\n",
      "Epoch 30/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 217.9470 - val_loss: 215.8025\n",
      "Epoch 31/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 210.0405 - val_loss: 205.1703\n",
      "Epoch 32/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 202.3353 - val_loss: 197.0203\n",
      "Epoch 33/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 195.3162 - val_loss: 188.4809\n",
      "Epoch 34/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 188.6290 - val_loss: 179.0785\n",
      "Epoch 35/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 181.5501 - val_loss: 170.8478\n",
      "Epoch 36/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 175.1744 - val_loss: 162.6766\n",
      "Epoch 37/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 169.0356 - val_loss: 155.5759\n",
      "Epoch 38/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 163.2789 - val_loss: 149.0858\n",
      "Epoch 39/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 157.8349 - val_loss: 141.9514\n",
      "Epoch 40/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 152.4565 - val_loss: 135.2438\n",
      "Epoch 41/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 147.5938 - val_loss: 130.0181\n",
      "Epoch 42/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 142.8127 - val_loss: 124.0045\n",
      "Epoch 43/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 138.3974 - val_loss: 118.4193\n",
      "Epoch 44/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 134.2874 - val_loss: 114.5075\n",
      "Epoch 45/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 130.2166 - val_loss: 108.7437\n",
      "Epoch 46/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 126.4253 - val_loss: 103.6722\n",
      "Epoch 47/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 122.9098 - val_loss: 100.2051\n",
      "Epoch 48/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 119.4569 - val_loss: 96.5124\n",
      "Epoch 49/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 116.1618 - val_loss: 92.6871\n",
      "Epoch 50/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 113.1890 - val_loss: 89.3191\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train_scaled,y_train,epochs=50,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "76349557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e5bb1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "83ff1f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7994154209273145"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
